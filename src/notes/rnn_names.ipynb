{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4e6666-07e6-4c81-8b3d-d55bf291b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29442fc-b9c9-4809-8415-eadfbc79f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        names = [\"James\", \"Mary\", \"Robert\", \"Patricia\", \"John\", \"Jennifer\", \"Michael\", \"Linda\", \"David\", \"Elizabeth\", \"William\", \"Barbara\", \"Richard\", \"Susan\", \"Joseph\", \"Jessica\", \"Thomas\", \"Sarah\", \"Christopher\", \"Karen\", \"Charles\", \"Lisa\", \"Daniel\", \"Nancy\", \"Matthew\", \"Betty\", \"Anthony\", \"Sandra\", \"Mark\", \"Margaret\", \"Donald\", \"Ashley\", \"Steven\", \"Kimberly\", \"Andrew\", \"Emily\", \"Paul\", \"Donna\", \"Joshua\", \"Michelle\", \"Kenneth\", \"Carol\", \"Kevin\", \"Amanda\", \"Brian\", \"Melissa\", \"George\", \"Deborah\", \"Timothy\", \"Stephanie\", \"Ronald\", \"Dorothy\", \"Jason\", \"Rebecca\", \"Edward\", \"Sharon\", \"Jeffrey\", \"Laura\", \"Ryan\", \"Cynthia\", \"Jacob\", \"Amy\", \"Gary\", \"Kathleen\", \"Nicholas\", \"Angela\", \"Eric\", \"Shirley\", \"Jonathan\", \"Brenda\", \"Stephen\", \"Emma\", \"Larry\", \"Anna\", \"Justin\", \"Pamela\", \"Scott\", \"Nicole\", \"Brandon\", \"Samantha\", \"Benjamin\", \"Katherine\", \"Samuel\", \"Christine\", \"Gregory\", \"Helen\", \"Alexander\", \"Debra\", \"Patrick\", \"Rachel\", \"Frank\", \"Carolyn\", \"Raymond\", \"Janet\", \"Jack\", \"Maria\", \"Dennis\", \"Catherine\", \"Jerry\", \"Heather\", \"Tyler\", \"Diane\", \"Aaron\", \"Olivia\", \"Jose\", \"Julie\", \"Adam\", \"Joyce\", \"Nathan\", \"Victoria\", \"Henry\", \"Ruth\", \"Zachary\", \"Virginia\", \"Douglas\", \"Lauren\", \"Peter\", \"Kelly\", \"Kyle\", \"Christina\", \"Noah\", \"Joan\", \"Ethan\", \"Evelyn\", \"Jeremy\", \"Judith\", \"Walter\", \"Andrea\", \"Christian\", \"Hannah\", \"Keith\", \"Megan\", \"Roger\", \"Cheryl\", \"Terry\", \"Jacqueline\", \"Austin\", \"Martha\", \"Sean\", \"Madison\", \"Gerald\", \"Teresa\", \"Carl\", \"Gloria\", \"Harold\", \"Sara\", \"Dylan\", \"Janice\", \"Arthur\", \"Ann\", \"Lawrence\", \"Kathryn\", \"Jordan\", \"Abigail\", \"Jesse\", \"Sophia\", \"Bryan\", \"Frances\", \"Billy\", \"Jean\", \"Bruce\", \"Alice\", \"Gabriel\", \"Judy\", \"Joe\", \"Isabella\", \"Logan\", \"Julia\", \"Alan\", \"Grace\", \"Juan\", \"Amber\", \"Albert\", \"Denise\", \"Willie\", \"Danielle\", \"Elijah\", \"Marilyn\", \"Wayne\", \"Beverly\", \"Randy\", \"Charlotte\", \"Vincent\", \"Natalie\", \"Mason\", \"Theresa\", \"Roy\", \"Diana\", \"Ralph\", \"Brittany\", \"Bobby\", \"Doris\", \"Russell\", \"Kayla\", \"Bradley\", \"Alexis\", \"Philip\", \"Lori\", \"Eugene\", \"Marie\"]\n",
    "        self.data = []\n",
    "        for name in names:\n",
    "            x = (CustomDataset.make_tensor(ch) for ch in name[:-1])\n",
    "            y = (CustomDataset.make_tensor(ch, dtype=torch.long) for ch in name[1:])\n",
    "            self.data.append((torch.stack(list(x)), torch.stack(list(y))))\n",
    "\n",
    "    @staticmethod\n",
    "    def make_tensor(ch, dtype=torch.float32):\n",
    "        tensor = torch.zeros(52, dtype=dtype)\n",
    "        if  ord('a') <= ord(ch) <= ord('z'):\n",
    "            tensor[ord(ch) - ord('a')] = 1 \n",
    "        if  ord('A') <= ord(ch) <= ord('Z'):\n",
    "            tensor[26 + ord(ch) - ord('A')] = 1 \n",
    "        return tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def from_tensor(tensor):\n",
    "        values, indices = torch.topk(tensor, k=1)\n",
    "        ch = indices[0].item()\n",
    "        return chr(ord('A') + ch - 26) if ch >= 26 else chr(ord('a') + ch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dataset = CustomDataset()\n",
    "test_dataset = CustomDataset()\n",
    "train = DataLoader(train_dataset, batch_size=1)\n",
    "test = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39af0f3-e027-4214-b778-6e1f36a27a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, state_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.i2s = torch.nn.Linear(self.input_size + self.state_size, self.state_size)\n",
    "        self.i2h = torch.nn.Linear(self.input_size + self.state_size, self.hidden_size)\n",
    "        self.h2h = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.h2o = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.dropout = torch.nn.Dropout(0.15)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=0)\n",
    "\n",
    "    def forward(self, i: torch.Tensor, state: torch.Tensor):\n",
    "        i_ = torch.cat((i, state))\n",
    "        s = self.i2s(i_)\n",
    "        h = self.i2h(i_)\n",
    "        h2 = self.h2h(torch.relu(h))\n",
    "        o = self.h2o(torch.relu(h2))\n",
    "        o = self.dropout(o)\n",
    "        return self.softmax(o), s\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84caadc2-0262-4e47-8ae9-f9662c525f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (batched_x, batched_y) in enumerate(dataloader):\n",
    "        cost = 0\n",
    "        for x, y in zip(batched_x, batched_y):\n",
    "            state = model.init_hidden()\n",
    "            for i, (x_, y_) in enumerate(zip(x, y)):\n",
    "                pred, state = model(x_, state)\n",
    "                cost += loss(pred, torch.argmax(y_))\n",
    "        cost.backward()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        batch_loss = cost.item() / (batched_x.size(0) * batched_x.size(1) * batched_x.size(2))\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss, epoch):\n",
    "    model.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batched_x, batched_y) in enumerate(dataloader):\n",
    "            batch_loss = 0\n",
    "            for x, y in zip(batched_x, batched_y):\n",
    "                state = model.init_hidden()\n",
    "                for x_, y_ in zip(x, y):\n",
    "                    pred, state = model(x_, state)\n",
    "                    batch_loss += loss(pred, torch.argmax(y_))\n",
    "            batch_loss /= batched_x.size(0) * batched_x.size(1) * batched_x.size(2)\n",
    "            test_loss += batch_loss\n",
    "    return test_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1729da11-0afd-4952-b426-d3eaaaaa5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------\n",
      "Epoch: 1\n",
      "Loss in training:  14.250948515203254\n",
      "Loss in test: 13.304386138916016\n",
      "---------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../out/rnn_names.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     17\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_loop(train, model, loss, optimizer, epoch)\n\u001b[0;32m---> 18\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, loss, epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m     state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit_hidden()\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_, y_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x, y):\n\u001b[0;32m---> 31\u001b[0m         pred, state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m         batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss(pred, torch\u001b[38;5;241m.\u001b[39margmax(y_))\n\u001b[1;32m     33\u001b[0m batch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m batched_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m batched_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batched_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/melowave-7lecoToH-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/melowave-7lecoToH-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mRNNetwork.forward\u001b[0;34m(self, i, state)\u001b[0m\n\u001b[1;32m     19\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi2h(i_)\n\u001b[1;32m     20\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2h(torch\u001b[38;5;241m.\u001b[39mrelu(h))\n\u001b[0;32m---> 21\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh2o\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(o)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(o), s\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/melowave-7lecoToH-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/melowave-7lecoToH-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1521\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1521\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tracing_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "STATE_SIZE = 20\n",
    "\n",
    "def main():\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    model = RNNetwork(26 * 2, 26 * 2, HIDDEN_SIZE, STATE_SIZE).to(device)\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train, model, loss, optimizer, epoch)\n",
    "        test_loss = test_loop(test, model, loss, epoch)\n",
    "\n",
    "        print(\"---------------\")\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        print(\"Loss in training: \", train_loss)\n",
    "        print(\"Loss in test:\", test_loss)\n",
    "        print(\"---------------\\n\")\n",
    "        \n",
    "    torch.save(model.state_dict(), \"../../out/rnn_names.pth\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa6e8e1-9efc-46d9-836a-a5aca2064825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter name:  jane\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l: 0.26\n",
      "r: 0.20\n",
      "n: 0.13\n",
      "t: 0.06\n",
      "s: 0.05\n",
      "\n",
      "Expected:  janel\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter name:  \n"
     ]
    }
   ],
   "source": [
    "def sandbox():\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using {device} device\")\n",
    "    model = RNNetwork(26 * 2, 26 * 2, HIDDEN_SIZE, STATE_SIZE).to(device)\n",
    "    model.load_state_dict(torch.load(\"../../out/rnn_names.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            try:\n",
    "                name = input(\"Enter name: \").strip()\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "\n",
    "            if name == \"\":\n",
    "                break\n",
    "\n",
    "            name_tensors = [CustomDataset.make_tensor(ch) for ch in name]\n",
    "\n",
    "            state = model.init_hidden()\n",
    "            pred = None\n",
    "            for tensor in name_tensors:\n",
    "                pred, state = model(tensor, state)\n",
    "\n",
    "            prob = torch.exp(pred)\n",
    "            prob = prob / torch.sum(prob)\n",
    "            for prob, idx in zip(*torch.topk(prob, k=5)):\n",
    "                ch = idx.item()\n",
    "                c = chr(ord('A') + ch - 26) if ch >= 26 else chr(ord('a') + ch)\n",
    "                print(f\"{c}: {prob.item():.2f}\")\n",
    "            print(\"\\nExpected: \", name + CustomDataset.from_tensor(pred))\n",
    "sandbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076506e-dd17-4e1e-aa97-a466c645a688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
