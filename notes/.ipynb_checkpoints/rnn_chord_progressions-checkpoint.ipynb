{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd90c8-af90-4029-8383-e720837f678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ceedd8-9237-4045-b76a-f15fdc9c0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "chord_vectors = KeyedVectors.load(\"../out/vectors.bin\")\n",
    "INPUT_SIZE = OUTPUT_SIZE = chord_vectors[\"C\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6cc2eb-a1c1-44e7-9fc7-42898a12a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UltimateGuitarSongDataset(Dataset):\n",
    "    def __init__(self, chord_vectors, filename=\"../out/chord_progressions.json\"):\n",
    "        with open(filename) as f:\n",
    "            songs = json.load(f)\n",
    "            assert isinstance(songs, list)\n",
    "\n",
    "        songs = [song[:8] for song in songs if len(song) > 8]\n",
    "\n",
    "        songs = [\n",
    "            [torch.from_numpy(chord_vectors[chord].copy()) for chord in song]\n",
    "            for song in songs\n",
    "        ]\n",
    "\n",
    "        self.data = []\n",
    "        for song in songs:\n",
    "            self.data.append((torch.stack(song[:-1]), torch.stack(song[1:])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "_, train_dataset, test_dataset = random_split(\n",
    "    UltimateGuitarSongDataset(chord_vectors), [0.00, 0.80, 0.20]\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d6158-22a4-4289-9443-86339e8352eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, state_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.i2s = torch.nn.Linear(self.input_size + self.state_size, self.state_size)\n",
    "        self.i2h = torch.nn.Linear(self.input_size + self.state_size, self.hidden_size)\n",
    "        self.h2h = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.h2o = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, i: torch.Tensor, state: torch.Tensor):\n",
    "        i_ = torch.cat((i, state))\n",
    "        s = self.i2s(i_)\n",
    "        h = self.i2h(i_)\n",
    "        h2 = self.h2h(torch.relu(h))\n",
    "        o = self.h2o(torch.relu(h2))\n",
    "        o = self.dropout(o)\n",
    "        return o, s\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197d93b-2f2d-4c17-9231-d6a2071a6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (batched_x, batched_y) in enumerate(dataloader):\n",
    "        cost = 0\n",
    "        for x, y in zip(batched_x, batched_y):\n",
    "            state = model.init_hidden()\n",
    "            for i, (x_, y_) in enumerate(zip(x, y)):\n",
    "                pred, state = model(x_, state)\n",
    "                cost += loss(pred, y_)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = cost.item() / (batched_x.size(0) * batched_x.size(1) * batched_x.size(2))\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Batch {batch_idx} loss: {batch_loss}\")\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss, wv, epoch):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    total_len = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batched_x, batched_y) in enumerate(dataloader):\n",
    "            batch_loss = 0\n",
    "            for x, y in zip(batched_x, batched_y):\n",
    "                state = model.init_hidden()\n",
    "                for x_, y_ in zip(x, y):\n",
    "                    pred, state = model(x_, state)\n",
    "                    batch_loss += loss(pred, y_)\n",
    "                    similar = wv.similar_by_vector(pred.numpy(), topn=3)\n",
    "                    if any(np.array_equal(wv[chord], y_) for chord, _ in similar):\n",
    "                        correct += 1\n",
    "            batch_loss /= batched_x.size(0) * batched_x.size(1) * batched_x.size(2)\n",
    "            test_loss += batch_loss\n",
    "            total_len += batched_x.size(0) * batched_x.size(1)\n",
    "\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f\"Test Batch {batch_idx} loss: {batch_loss}\")\n",
    "    correct = correct / total_len * 100\n",
    "    print(f\"Accuracy: {correct:>0.1f}, Average Loss: {test_loss:>8f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fcea6-44fb-48d7-b8c7-e217780ef121",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "STATE_SIZE = 20\n",
    "\n",
    "def main():\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    model = RNNetwork(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE, STATE_SIZE).to(device)\n",
    "    loss = nn.MSELoss()\n",
    "    learning_rate = 0.001\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        print(\"---------------\")\n",
    "        cost = train_loop(train_dataloader, model, loss, optimizer, epoch)\n",
    "        print(\"Loss in training: \", cost)\n",
    "        test_loop(test_dataloader, model, loss, chord_vectors, epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), \"../out/rnn_chord_progressions.pth\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad4e8f-f064-4d54-83cd-4e8c6d936291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using {device} device\")\n",
    "    model = RNNetwork(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE, STATE_SIZE).to(device)\n",
    "    model.load_state_dict(torch.load(\"../out/rnn_chord_progressions.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            try:\n",
    "                chord_sequence_str = input(\"Enter chord sequence: \").strip()\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "\n",
    "            if chord_sequence_str == \"\":\n",
    "                break\n",
    "\n",
    "            chord_sequence = [\n",
    "                torch.from_numpy(np.copy(chord_vectors[c]))\n",
    "                for c in chord_sequence_str.split()\n",
    "            ]\n",
    "\n",
    "            state = model.init_hidden()\n",
    "            pred = None\n",
    "            for chord in chord_sequence:\n",
    "                pred, state = model(chord, state)\n",
    "            similar = chord_vectors.similar_by_vector(pred.numpy(), topn=6)\n",
    "            chords, _ = zip(*similar)\n",
    "            print(chords)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed542c7b-06aa-4e6c-92c4-722025ab4681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
