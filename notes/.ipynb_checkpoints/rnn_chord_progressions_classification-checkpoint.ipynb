{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e6666-07e6-4c81-8b3d-d55bf291b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29442fc-b9c9-4809-8415-eadfbc79f10e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class UltimateGuitarSongDataset(Dataset):\n",
    "    def __init__(self, filename=\"../out/chord_progressions.json\"):\n",
    "        with open(filename) as f:\n",
    "            songs = json.load(f)\n",
    "            assert isinstance(songs, list)\n",
    "\n",
    "        songs = [song[:8] for song in songs if len(song) > 8]\n",
    "        \n",
    "        self.unique_chords = sorted(list(functools.reduce(lambda acc, x: acc | set(x), songs, set())))\n",
    "\n",
    "        self.unique_chords_to_tensors = {}\n",
    "        for i, chord in enumerate(self.unique_chords):\n",
    "            tensor = torch.zeros(len(self.unique_chords), dtype=torch.long)\n",
    "            tensor[i] = 1\n",
    "            self.unique_chords_to_tensors[chord] = tensor\n",
    "\n",
    "        self.data = []\n",
    "        for song in songs:\n",
    "            x = (self.unique_chords_to_tensors[chord] for chord in song[:-1])\n",
    "            y = (self.unique_chords_to_tensors[chord] for chord in song[1:])\n",
    "            self.data.append((torch.stack(list(x)), torch.stack(list(y))))        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = UltimateGuitarSongDataset()\n",
    "_, train_dataset, test_dataset = random_split(dataset, [0.0, 0.80, 0.20])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "INPUT_SIZE = OUTPUT_SIZE = len(dataset.unique_chords)\n",
    "print(f\"Input size: {INPUT_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39af0f3-e027-4214-b778-6e1f36a27a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, state_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.i2s = torch.nn.Linear(self.input_size + self.state_size, self.state_size)\n",
    "        self.i2h = torch.nn.Linear(self.input_size + self.state_size, self.hidden_size)\n",
    "        self.h2h = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.h2o = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.dropout = torch.nn.Dropout(0.10)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=0)\n",
    "\n",
    "    def forward(self, i: torch.Tensor, state: torch.Tensor):\n",
    "        i_ = torch.cat((i, state))\n",
    "        s = self.i2s(i_)\n",
    "        h = self.i2h(i_)\n",
    "        h2 = self.h2h(torch.relu(h))\n",
    "        o = self.h2o(torch.relu(h2))\n",
    "        o = self.dropout(o)\n",
    "        return self.softmax(o), s\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84caadc2-0262-4e47-8ae9-f9662c525f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (batched_x, batched_y) in enumerate(dataloader):\n",
    "        cost = 0\n",
    "        for x, y in zip(batched_x, batched_y):\n",
    "            state = model.init_hidden()\n",
    "            for i, (x_, y_) in enumerate(zip(x, y)):\n",
    "                pred, state = model(x_, state)\n",
    "                cost += loss(pred, torch.argmax(y_))\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss = cost.item() / (batched_x.size(0) * batched_x.size(1) * batched_x.size(2))\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx} loss: {batch_loss}\")\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss, epoch):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    total_items = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batched_x, batched_y) in enumerate(dataloader):\n",
    "            batch_loss = 0\n",
    "            for x, y in zip(batched_x, batched_y):\n",
    "                state = model.init_hidden()\n",
    "                for x_, y_ in zip(x, y):\n",
    "                    pred, state = model(x_, state)\n",
    "                    batch_loss += loss(pred, torch.argmax(y_))\n",
    "\n",
    "                    # Accuracy count\n",
    "                    _, indices = torch.topk(pred, k=3)\n",
    "                    if torch.argmax(y_).item() in indices:\n",
    "                        correct += 1\n",
    "            batch_loss /= batched_x.size(0) * batched_x.size(1) * batched_x.size(2)\n",
    "            test_loss += batch_loss\n",
    "            total_items += batched_x.size(0) * batched_x.size(1)\n",
    "        accuracy = 100 * correct / total_items\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    return test_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729da11-0afd-4952-b426-d3eaaaaa5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "STATE_SIZE = 20\n",
    "\n",
    "def main():\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    model = RNNetwork(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE, STATE_SIZE).to(device)\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dataloader, model, loss, optimizer, epoch)\n",
    "        test_loss = test_loop(test_dataloader, model, loss, epoch)\n",
    "\n",
    "        print(\"---------------\")\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        print(\"Loss in training: \", train_loss)\n",
    "        print(\"Loss in test:\", test_loss)\n",
    "        print(\"---------------\\n\")\n",
    "        \n",
    "    torch.save(model.state_dict(), \"../out/rnn_chord_progressions_classification.pth\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6e8e1-9efc-46d9-836a-a5aca2064825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sandbox():\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using {device} device\")\n",
    "    model = RNNetwork(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE, STATE_SIZE).to(device)\n",
    "    model.load_state_dict(torch.load(\"../out/rnn_chord_progressions_classification.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            try:\n",
    "                chord_progression = input(\"Enter chord progression: \").strip()\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "\n",
    "            if chord_progression == \"\":\n",
    "                break\n",
    "\n",
    "            chord_tensors = [dataset.unique_chords_to_tensors[chord] for chord in chord_progression.split()]\n",
    "\n",
    "            state = model.init_hidden()\n",
    "            pred = None\n",
    "            for tensor in chord_tensors:\n",
    "                pred, state = model(tensor, state)\n",
    "\n",
    "            prob = torch.exp(pred)\n",
    "            prob = prob / torch.sum(prob)\n",
    "            for prob, idx in zip(*torch.topk(prob, k=5)):\n",
    "                idx = idx.item()\n",
    "                chord = dataset.unique_chords[idx]\n",
    "                print(f\"{chord}: {prob.item():.2f}\")\n",
    "            print(\"\\nExpected: \", chord_progression + \" \" + dataset.unique_chords[torch.argmax(pred).item()])\n",
    "sandbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076506e-dd17-4e1e-aa97-a466c645a688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
